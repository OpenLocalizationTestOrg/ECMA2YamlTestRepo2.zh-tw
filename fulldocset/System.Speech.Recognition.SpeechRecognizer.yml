### YamlMime:ManagedReference
items:
- uid: System.Speech.Recognition.SpeechRecognizer
  id: SpeechRecognizer
  children:
  - System.Speech.Recognition.SpeechRecognizer.#ctor
  - System.Speech.Recognition.SpeechRecognizer.AudioFormat
  - System.Speech.Recognition.SpeechRecognizer.AudioLevel
  - System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated
  - System.Speech.Recognition.SpeechRecognizer.AudioPosition
  - System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred
  - System.Speech.Recognition.SpeechRecognizer.AudioState
  - System.Speech.Recognition.SpeechRecognizer.AudioStateChanged
  - System.Speech.Recognition.SpeechRecognizer.Dispose
  - System.Speech.Recognition.SpeechRecognizer.Dispose(System.Boolean)
  - System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)
  - System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  - System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)
  - System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)
  - System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  - System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)
  - System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted
  - System.Speech.Recognition.SpeechRecognizer.Enabled
  - System.Speech.Recognition.SpeechRecognizer.Grammars
  - System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)
  - System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)
  - System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted
  - System.Speech.Recognition.SpeechRecognizer.MaxAlternates
  - System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition
  - System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition
  - System.Speech.Recognition.SpeechRecognizer.RecognizerInfo
  - System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached
  - System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate
  - System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)
  - System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)
  - System.Speech.Recognition.SpeechRecognizer.SpeechDetected
  - System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized
  - System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected
  - System.Speech.Recognition.SpeechRecognizer.SpeechRecognized
  - System.Speech.Recognition.SpeechRecognizer.State
  - System.Speech.Recognition.SpeechRecognizer.StateChanged
  - System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars
  - System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)
  langs:
  - csharp
  name: SpeechRecognizer
  nameWithType: SpeechRecognizer
  fullName: System.Speech.Recognition.SpeechRecognizer
  type: Class
  summary: "在 Windows 桌面上提供存取權可用的共用的語音辨識服務。"
  remarks: "應用程式會使用共用辨識器來存取 Windows 語音辨識。 用於 SpeechRecognizer 物件新增至 Windows 語音使用者經驗。       這個類別提供控制語音辨識程序的各個層面:-若要管理 語音辨識文法，請使用<xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A>， <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A>， <xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A>， <xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A>，和<xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A>。</xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A> </xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A> </xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A> </xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A> </xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A>      -若要取得目前的語音資訊辨識作業，請訂閱 SpeechRecognizer <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>， <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>， <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>，和<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>事件。</xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>      -若要檢視或修改替代的辨識器傳回的結果數目，請使用<xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A>屬性。</xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A> 辨識器傳回辨識導致<xref:System.Speech.Recognition.RecognitionResult>物件。</xref:System.Speech.Recognition.RecognitionResult>      -若要存取，或監視共用辨識器的狀態，請使用<xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A>， <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>， <xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A>， <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A>， <xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A>， <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>，和<xref:System.Speech.Recognition.SpeechRecognizer.State%2A>屬性和<xref:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated>， <xref:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred>， <xref:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged>，和<xref:System.Speech.Recognition.SpeechRecognizer.StateChanged>事件。</xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> </xref:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged> </xref:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred> </xref:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated> </xref:System.Speech.Recognition.SpeechRecognizer.State%2A> </xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> </xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A> </xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A> </xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A> </xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> </xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A>      -若要變更同步至辨識器，使用<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>方法。</xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> 共用辨識器會使用多個執行緒執行工作。      -若要模擬共用辨識器的輸入，使用<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A>和<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>方法。</xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A>       Windows 語音辨識的組態使用由管理**語音內容**對話方塊**控制台**。 這個介面用來選取預設桌面的語音辨識引擎和語言、 音訊輸入的裝置和語音辨識的睡眠行為。 如果 Windows 語音辨識] 的組態變更應用程式執行期間，（比方說，如果已停用 [語音辨識，或輸入的語言變更），變更會影響所有 SpeechRecognizer 物件。       若要建立獨立於 Windows 語音辨識同處理序語音辨識器，使用<xref:System.Speech.Recognition.SpeechRecognitionEngine>類別。</xref:System.Speech.Recognition.SpeechRecognitionEngine>      > [!NOTE] > 永遠呼叫<xref:System.Speech.Recognition.SpeechRecognizer.Dispose%2A>釋放語音辨識器您最後一個參考之前。</xref:System.Speech.Recognition.SpeechRecognizer.Dispose%2A> 否則，它所使用的資源將不會釋放記憶體回收行程呼叫辨識器物件的直到`Finalize`方法。"
  example:
  - "The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.  If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition. If Windows Speech Recognition is in the **Sleeping** state, then <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> always returns null.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace SharedRecognizer  \n{  \n  class Program  \n  {  \n  \n    // Indicate whether the asynchronous emulate recognition  \n    // operation has completed.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n  \n      // Initialize an instance of the shared recognizer.  \n      using (SpeechRecognizer recognizer = new SpeechRecognizer())  \n      {  \n  \n        // Create and load a sample grammar.  \n        Grammar testGrammar =  \n          new Grammar(new GrammarBuilder(\"testing testing\"));  \n        testGrammar.Name = \"Test Grammar\";  \n        recognizer.LoadGrammar(testGrammar);  \n  \n        // Attach event handlers for recognition events.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.EmulateRecognizeCompleted +=  \n          new EventHandler<EmulateRecognizeCompletedEventArgs>(  \n            EmulateRecognizeCompletedHandler);  \n  \n        completed = false;  \n  \n        // Start asynchronous emulated recognition.   \n        // This matches the grammar and generates a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing testing\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n  \n        completed = false;  \n  \n        // Start asynchronous emulated recognition.  \n        // This does not match the grammar or generate a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing one two three\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"Recognition result = {0}\",  \n          e.Result.Text ?? \"<no text>\");  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No recognition result\");  \n      }  \n    }  \n  \n    // Handle the SpeechRecognizeCompleted event.  \n    static void EmulateRecognizeCompletedHandler(  \n      object sender, EmulateRecognizeCompletedEventArgs e)  \n    {  \n      if (e.Result == null)  \n      {  \n        Console.WriteLine(\"No result generated.\");  \n      }  \n  \n      // Indicate the asynchronous operation is complete.  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: 'public class SpeechRecognizer : IDisposable'
  inheritance:
  - System.Object
  implements:
  - System.IDisposable
  inheritedMembers: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.#ctor
  id: '#ctor'
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: SpeechRecognizer()
  nameWithType: SpeechRecognizer.SpeechRecognizer()
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechRecognizer()
  type: Constructor
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "初始化的新執行個體<xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;></xref>類別。"
  remarks: "每個<xref:System.Speech.Recognition.SpeechRecognizer>物件會維護一組個別的語音辨識文法。</xref:System.Speech.Recognition.SpeechRecognizer>"
  example:
  - "The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer. If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition. If Windows Speech Recognition is in the **Sleeping** state, then <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> always returns null.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace SharedRecognizer  \n{  \n  class Program  \n  {  \n  \n    // Indicate whether the asynchronous emulate recognition  \n    // operation has completed.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n  \n      // Initialize an instance of the shared recognizer.  \n      using (SpeechRecognizer recognizer = new SpeechRecognizer())  \n      {  \n  \n        // Create and load a sample grammar.  \n        Grammar testGrammar =  \n          new Grammar(new GrammarBuilder(\"testing testing\"));  \n        testGrammar.Name = \"Test Grammar\";  \n        recognizer.LoadGrammar(testGrammar);  \n  \n        // Attach event handlers for recognition events.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.EmulateRecognizeCompleted +=  \n          new EventHandler<EmulateRecognizeCompletedEventArgs>(  \n            EmulateRecognizeCompletedHandler);  \n  \n        completed = false;  \n  \n        // Start asynchronous emulated recognition.   \n        // This matches the grammar and generates a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing testing\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n  \n        completed = false;  \n  \n        // Start asynchronous emulated recognition.  \n        // This does not match the grammar or generate a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing one two three\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"Recognition result = {0}\",  \n          e.Result.Text ?? \"<no text>\");  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No recognition result\");  \n      }  \n    }  \n  \n    // Handle the SpeechRecognizeCompleted event.  \n    static void EmulateRecognizeCompletedHandler(  \n      object sender, EmulateRecognizeCompletedEventArgs e)  \n    {  \n      if (e.Result == null)  \n      {  \n        Console.WriteLine(\"No result generated.\");  \n      }  \n  \n      // Indicate the asynchronous operation is complete.  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public SpeechRecognizer ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognizer.#ctor*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.AudioFormat
  id: AudioFormat
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: AudioFormat
  nameWithType: SpeechRecognizer.AudioFormat
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioFormat
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "取得語音辨識器接收的音訊格式。"
  syntax:
    content: public System.Speech.AudioFormat.SpeechAudioFormatInfo AudioFormat { get; }
    return:
      type: System.Speech.AudioFormat.SpeechAudioFormatInfo
      description: "語音辨識器的音訊輸入的格式或<xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>如果辨識器的輸入未設定。"
  overload: System.Speech.Recognition.SpeechRecognizer.AudioFormat*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.AudioLevel
  id: AudioLevel
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: AudioLevel
  nameWithType: SpeechRecognizer.AudioLevel
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioLevel
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "取得語音辨識器接收的音訊層級。"
  syntax:
    content: public int AudioLevel { get; }
    return:
      type: System.Int32
      description: "音訊的層級的語音辨識器中，輸入 0 到 100 之間。"
  overload: System.Speech.Recognition.SpeechRecognizer.AudioLevel*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated
  id: AudioLevelUpdated
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: AudioLevelUpdated
  nameWithType: SpeechRecognizer.AudioLevelUpdated
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "當共用辨識器報告其音訊的輸入層級。"
  remarks: "辨識器會引發此事件每秒多次。 用來引發事件的頻率取決於應用程式執行所在的電腦。       若要取得的音訊的層級事件時，使用<xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A>相關聯的<xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs>.</xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs>屬性</xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A> 若要取得目前音訊的辨識器的輸入層級，使用的辨識器<xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A>屬性。</xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A>       當您建立的委派`AudioLevelUpdated`事件，必須識別處理事件的方法。 若要將事件與事件處理常式產生關聯，將委派的執行個體加入事件。 除非您移除委派，否則每當事件發生時，會呼叫事件處理常式。 如需事件處理常式委派的詳細資訊，請參閱[事件和委派](http://go.microsoft.com/fwlink/?LinkId=162418)。"
  example:
  - "The following example adds a handler for the `AudioLevelUpdated` event to a <xref:System.Speech.Recognition.SpeechRecognizer> object. The handler outputs the new audio level to the console.  \n  \n```c#  \nprivate SpeechRecognizer recognizer;  \n  \n// Initialize the SpeechRecognizer object.   \nprivate void Initialize()  \n{  \n  recognizer = new SpeechRecognizer();  \n  \n  // Add an event handler for the AudioLevelUpdated event.  \n  recognizer.AudioLevelUpdated +=   \n    new EventHandler<AudioLevelUpdatedEventArgs>(recognizer_AudioLevelUpdated);  \n  \n  // Add other initialization code here.  \n  \n}  \n  \n// Write the audio level to the console when the AudioLevelUpdated event is raised.  \nvoid recognizer_AudioLevelUpdated(object sender, AudioLevelUpdatedEventArgs e)  \n{  \n  Console.WriteLine(\"The audio level is now: {0}.\", e.AudioLevel);  \n}  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.AudioLevelUpdatedEventArgs> AudioLevelUpdated;
    return:
      type: System.EventHandler{System.Speech.Recognition.AudioLevelUpdatedEventArgs}
      description: "即將加入。"
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.AudioPosition
  id: AudioPosition
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: AudioPosition
  nameWithType: SpeechRecognizer.AudioPosition
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioPosition
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "取得提供輸入到 語音辨識器的裝置所產生的音訊資料流中目前的位置。"
  remarks: "共用辨識器接收輸入桌面的語音辨識 正在執行時。       `AudioPosition`屬性會參考其產生的音訊資料流中的輸入的裝置的位置。 相反地，<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>屬性會參考在處理音訊輸入辨識器的位置。</xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> 這些位置可能會不同。  例如，如果辨識器已接收輸入它具有不尚未產生辨識結果，則值<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>屬性小於 AudioPosition 屬性的值。</xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>"
  example:
  - "In the following example, the shared speech recognizer uses a dictation grammar to match speech input. A handler for the <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected> event writes to the console the AudioPosition, <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>, and  <xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A> when the speech recognizer detects speech at its input.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    private static SpeechRecognizer recognizer;  \n    public static void Main(string[] args)  \n    {  \n  \n      // Initialize a shared speech recognition engine.  \n      recognizer = new SpeechRecognizer();  \n  \n      // Add handlers for events.  \n      recognizer.LoadGrammarCompleted +=   \n        new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n      recognizer.SpeechRecognized +=   \n        new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n      recognizer.StateChanged +=   \n        new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  \n      recognizer.SpeechDetected +=   \n        new EventHandler<SpeechDetectedEventArgs>(recognizer_SpeechDetected);  \n  \n      // Create a dictation grammar.  \n      Grammar dictation = new DictationGrammar();  \n      dictation.Name = \"Dictation\";  \n  \n      // Load the grammar object to the recognizer.  \n      recognizer.LoadGrammarAsync(dictation);  \n  \n      // Keep the console window open.  \n      Console.ReadLine();  \n    }  \n  \n    // Gather information about detected speech and write it to the console.  \n    static void recognizer_SpeechDetected(object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine();  \n      Console.WriteLine(\"Speech detected:\");  \n      Console.WriteLine(\"  Audio level: \" + recognizer.AudioLevel);  \n      Console.WriteLine(\"  Audio position: \" + recognizer.AudioPosition);  \n      Console.WriteLine(\"  Recognizer audio position: \" + recognizer.RecognizerAudioPosition);  \n    }  \n  \n    // Write the text of the recognition result to the console.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {   \n      Console.WriteLine(\"Speech recognized: \" + e.Result.Text);  \n  \n      // Add event handler code here.  \n    }  \n  \n    // Write the name of the loaded grammar to the console.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n    }  \n  \n    // Put the shared speech recognizer into \"listening\" mode.  \n    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  \n    {  \n      if (e.RecognizerState != RecognizerState.Stopped)  \n      {  \n        recognizer.EmulateRecognizeAsync(\"Start listening\");  \n      }  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public TimeSpan AudioPosition { get; }
    return:
      type: System.TimeSpan
      description: "語音辨識器音訊輸入資料流中，已接收輸入目前的位置。"
  overload: System.Speech.Recognition.SpeechRecognizer.AudioPosition*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred
  id: AudioSignalProblemOccurred
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: AudioSignalProblemOccurred
  nameWithType: SpeechRecognizer.AudioSignalProblemOccurred
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "發生於辨識器遇到音訊訊號中的問題。"
  remarks: "若要取得哪些問題發生，請使用 <xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A>相關聯的<xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>.</xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>屬性</xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A>       當您建立的委派`AudioSignalProblemOccurred`事件，必須識別處理事件的方法。 若要將事件與事件處理常式產生關聯，將委派的執行個體加入事件。 除非您移除委派，否則每當事件發生時，會呼叫事件處理常式。 如需事件處理常式委派的詳細資訊，請參閱[事件和委派](http://go.microsoft.com/fwlink/?LinkId=162418)。"
  example:
  - "The following example defines an event handler that gathers information about an `AudioSignalProblemOccurred` event.  \n  \n```  \nprivate SpeechRecognizer recognizer;  \n  \n// Initialize the speech recognition engine.  \nprivate void Initialize()  \n{  \n  recognizer = new SpeechRecognizer();  \n  \n  // Add a handler for the AudioSignalProblemOccurred event.  \n  recognizer.AudioSignalProblemOccurred +=   \n    new EventHandler<AudioSignalProblemOccurredEventArgs>(  \n      recognizer_AudioSignalProblemOccurred);  \n}  \n  \n// Gather information when the AudioSignalProblemOccurred event is raised.  \nvoid recognizer_AudioSignalProblemOccurred(object sender, AudioSignalProblemOccurredEventArgs e)  \n{  \n  StringBuilder details = new StringBuilder();  \n  \n  details.AppendLine(\"Audio signal problem information:\");  \n  details.AppendFormat(  \n    \" Audio level:               {0}\" + Environment.NewLine +  \n    \" Audio position:            {1}\" + Environment.NewLine +  \n    \" Audio signal problem:      {2}\" + Environment.NewLine +  \n    \" Recognition engine audio position: {3}\" + Environment.NewLine,  \n    e.AudioLevel, e.AudioPosition,  e.AudioSignalProblem,  \n    e.recoEngineAudioPosition);  \n  \n  // Insert additional event handler code here.  \n}  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.AudioSignalProblemOccurredEventArgs> AudioSignalProblemOccurred;
    return:
      type: System.EventHandler{System.Speech.Recognition.AudioSignalProblemOccurredEventArgs}
      description: "即將加入。"
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.AudioState
  id: AudioState
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: AudioState
  nameWithType: SpeechRecognizer.AudioState
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioState
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "取得語音辨識器接收的音訊的狀態。"
  syntax:
    content: public System.Speech.Recognition.AudioState AudioState { get; }
    return:
      type: System.Speech.Recognition.AudioState
      description: "音訊輸入語音辨識器的狀態。"
  overload: System.Speech.Recognition.SpeechRecognizer.AudioState*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.AudioStateChanged
  id: AudioStateChanged
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: AudioStateChanged
  nameWithType: SpeechRecognizer.AudioStateChanged
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioStateChanged
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "當辨識器收到音訊中的狀態變更時，就會發生。"
  remarks: "若要取得的音訊狀態事件時，使用<xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A>相關聯的<xref:System.Speech.Recognition.AudioStateChangedEventArgs>.</xref:System.Speech.Recognition.AudioStateChangedEventArgs>屬性</xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A> 若要取得辨識器的輸入音訊的目前狀態，請使用 辨識器<xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A>屬性。</xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A> 如需音訊狀態的詳細資訊，請參閱<xref:System.Speech.Recognition.AudioState>列舉型別。</xref:System.Speech.Recognition.AudioState>       當您建立的委派`AudioStateChanged`事件，必須識別處理事件的方法。 若要將事件與事件處理常式產生關聯，將委派的執行個體加入事件。 除非您移除委派，否則每當事件發生時，會呼叫事件處理常式。 如需事件處理常式委派的詳細資訊，請參閱[事件和委派](http://go.microsoft.com/fwlink/?LinkId=162418)。"
  example:
  - "The following example uses a handler for the `AudioStateChanged` event to write the recognizer's new <xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A> to the console each time it changes using a member of the <xref:System.Speech.Recognition.AudioState> enumeration.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    private static SpeechRecognizer recognizer;  \n    public static void Main(string[] args)  \n    {  \n  \n      // Initialize a shared speech recognition engine.  \n      recognizer = new SpeechRecognizer();  \n  \n        // Create and load a grammar.  \n        Grammar dictation = new DictationGrammar();  \n        dictation.Name = \"Dictation Grammar\";  \n        recognizer.LoadGrammar(dictation);  \n  \n        // Attach event handlers.  \n        recognizer.AudioStateChanged +=  \n          new EventHandler<AudioStateChangedEventArgs>(recognizer_AudioStateChanged);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.StateChanged +=  \n          new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n  \n    // Handle the AudioStateChanged event.  \n    static void recognizer_AudioStateChanged(object sender, AudioStateChangedEventArgs e)  \n    {  \n      Console.WriteLine(\"The new audio state is: \" + e.AudioState);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null && e.Result.Text != null)  \n      {  \n        Console.WriteLine();  \n        Console.WriteLine(\"  Recognized text =  {0}\", e.Result.Text);  \n        Console.WriteLine();  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  Recognized text not available.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Done.\");  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Put the recognizer into Listening mode.  \n    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  \n    {  \n      if (e.RecognizerState != RecognizerState.Stopped)  \n      {  \n        Console.WriteLine();  \n        recognizer.EmulateRecognizeAsync(\"Start listening\");  \n      }  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.AudioStateChangedEventArgs> AudioStateChanged;
    return:
      type: System.EventHandler{System.Speech.Recognition.AudioStateChangedEventArgs}
      description: "即將加入。"
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.Dispose
  id: Dispose
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: Dispose()
  nameWithType: SpeechRecognizer.Dispose()
  fullName: System.Speech.Recognition.SpeechRecognizer.Dispose()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "處置<xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;></xref>物件。"
  syntax:
    content: public void Dispose ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognizer.Dispose*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.Dispose(System.Boolean)
  id: Dispose(System.Boolean)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: Dispose(Boolean)
  nameWithType: SpeechRecognizer.Dispose(Boolean)
  fullName: System.Speech.Recognition.SpeechRecognizer.Dispose(Boolean)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "處置<xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;></xref>工作階段期間使用的物件，並釋放資源。"
  syntax:
    content: protected virtual void Dispose (bool disposing);
    parameters:
    - id: disposing
      type: System.Boolean
      description: "<xref uid=&quot;langword_csharp_true&quot; name=&quot;true&quot; href=&quot;&quot;></xref>表示釋放 managed 和 unmanaged 資源，<xref uid=&quot;langword_csharp_false&quot; name=&quot;false&quot; href=&quot;&quot;> </xref>表示只釋放 unmanaged 的資源。"
  overload: System.Speech.Recognition.SpeechRecognizer.Dispose*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)
  id: EmulateRecognize(System.String)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: EmulateRecognize(String)
  nameWithType: SpeechRecognizer.EmulateRecognize(String)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(String)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "模擬片語的共用的語音辨識器，而不音訊使用文字同步語音辨識的輸入。"
  remarks: "隨附於 Vista 和 Windows 7 的辨識器忽略大小寫，並將文法規則套用至輸入的片語時，字元寬度。 如需這種類型的比較的詳細資訊，請參閱的<xref:System.Globalization.CompareOptions>列舉值<xref:System.Globalization.CompareOptions>和<xref:System.Globalization.CompareOptions>。</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> 辨識器也會忽略新行和額外的空白字元和標點符號視為常值的輸入。"
  example:
  - "The following example loads a sample grammar to the shared recognizer and emulates input to the recognizer. If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition. If Windows Speech Recognition is in the **Sleeping** state, then <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A> always returns null.  \n  \n```c#  \n  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SharedRecognizer  \n{  \n  class Program  \n  {  \n  \n    static void Main(string[] args)  \n    {  \n      // Initialize an instance of the shared recognizer.  \n      using (SpeechRecognizer recognizer = new SpeechRecognizer())  \n      {  \n        // Create and load a sample grammar.  \n        Grammar testGrammar =  \n          new Grammar(new GrammarBuilder(\"testing testing\"));  \n        testGrammar.Name = \"Test Grammar\";  \n  \n        recognizer.LoadGrammar(testGrammar);  \n  \n        RecognitionResult result;  \n  \n        // This EmulateRecognize call matches the grammar and returns a  \n        // recognition result.  \n        result = recognizer.EmulateRecognize(\"testing testing\");  \n        OutputResult(result);  \n  \n        // This EmulateRecognize call does not match the grammar and   \n        // returns null.  \n        result = recognizer.EmulateRecognize(\"testing one two three\");  \n        OutputResult(result);  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Output information about a recognition result to the console.  \n    private static void OutputResult(RecognitionResult result)  \n    {  \n      if (result != null)  \n      {  \n        Console.WriteLine(\"Recognition result = {0}\",  \n          result.Text ?? \"<no text>\");  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No recognition result\");  \n      }  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public System.Speech.Recognition.RecognitionResult EmulateRecognize (string inputText);
    parameters:
    - id: inputText
      type: System.String
      description: "輸入辨識作業。"
    return:
      type: System.Speech.Recognition.RecognitionResult
      description: "辨識結果辨識的操作，或<xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref>，如果作業未順利完成，或是 Windows 語音辨識**想念你**狀態。"
  overload: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  id: EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  nameWithType: SpeechRecognizer.EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "模擬的特定文字的共用的語音辨識器，使用同步的語音辨識，而不音訊文字輸入，並指定辨識器如何處理之間的單字與載入的語音辨識文法的 Unicode 比較。"
  remarks: "這個方法會建立<xref:System.Speech.Recognition.RecognitionResult>物件使用所提供的資訊`wordUnits`參數。</xref:System.Speech.Recognition.RecognitionResult>       使用辨識器`compareOptions`套用文法規則進行剖析的輸入句子。 隨附於 Vista 和 Windows 7 的辨識器會忽略大小寫，如果<xref:System.Globalization.CompareOptions>或<xref:System.Globalization.CompareOptions>值存在於。</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> 辨識器一律忽略字元寬度，並永遠不會忽略假名類型。 辨識器也會忽略新行和額外的空白字元和標點符號視為常值的輸入。 如需全半形字元和假名類型的詳細資訊，請參閱<xref:System.Globalization.CompareOptions>列舉型別。</xref:System.Globalization.CompareOptions>"
  syntax:
    content: public System.Speech.Recognition.RecognitionResult EmulateRecognize (System.Speech.Recognition.RecognizedWordUnit[] wordUnits, System.Globalization.CompareOptions compareOptions);
    parameters:
    - id: wordUnits
      type: System.Speech.Recognition.RecognizedWordUnit[]
      description: "Word 單位的陣列，其中包含將辨識作業的輸入。"
    - id: compareOptions
      type: System.Globalization.CompareOptions
      description: "描述要用於模擬的辨識作業的比較類型的列舉值的位元組合。"
    return:
      type: System.Speech.Recognition.RecognitionResult
      description: "辨識結果辨識的操作，或<xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref>，如果作業未順利完成，或是 Windows 語音辨識**想念你**狀態。"
  overload: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)
  id: EmulateRecognize(System.String,System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: EmulateRecognize(String,CompareOptions)
  nameWithType: SpeechRecognizer.EmulateRecognize(String,CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(String,CompareOptions)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "模擬片語的共用的語音辨識器，而不音訊使用文字同步語音辨識的輸入，並指定辨識器如何處理片語與載入的語音辨識文法的 Unicode 比較。"
  remarks: "使用辨識器`compareOptions`套用文法規則進行剖析的輸入句子。 隨附於 Vista 和 Windows 7 的辨識器會忽略大小寫，如果<xref:System.Globalization.CompareOptions>或<xref:System.Globalization.CompareOptions>值存在於。</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> 辨識器一律忽略字元寬度，並永遠不會忽略假名類型。 辨識器也會忽略新行和額外的空白字元和標點符號視為常值的輸入。 如需全半形字元和假名類型的詳細資訊，請參閱<xref:System.Globalization.CompareOptions>列舉型別。</xref:System.Globalization.CompareOptions>"
  syntax:
    content: public System.Speech.Recognition.RecognitionResult EmulateRecognize (string inputText, System.Globalization.CompareOptions compareOptions);
    parameters:
    - id: inputText
      type: System.String
      description: "輸入的辨識作業的片語。"
    - id: compareOptions
      type: System.Globalization.CompareOptions
      description: "描述要用於模擬的辨識作業的比較類型的列舉值的位元組合。"
    return:
      type: System.Speech.Recognition.RecognitionResult
      description: "辨識結果辨識的操作，或<xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref>，如果作業未順利完成，或是 Windows 語音辨識**想念你**狀態。"
  overload: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)
  id: EmulateRecognizeAsync(System.String)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: EmulateRecognizeAsync(String)
  nameWithType: SpeechRecognizer.EmulateRecognizeAsync(String)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(String)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "模擬片語的共用的語音辨識器，而不音訊的文字用於非同步語音辨識的輸入。"
  remarks: "隨附於 Vista 和 Windows 7 的辨識器忽略大小寫，並將文法規則套用至輸入的片語時，字元寬度。 如需這種類型的比較的詳細資訊，請參閱的<xref:System.Globalization.CompareOptions>列舉值<xref:System.Globalization.CompareOptions>和<xref:System.Globalization.CompareOptions>。</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> 辨識器也會忽略新行和額外的空白字元和標點符號視為常值的輸入。"
  example:
  - "The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer. If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition. If Windows Speech Recognition is in the **Sleeping** state, then <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> always returns null.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace SharedRecognizer  \n{  \n  class Program  \n  {  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n      // Initialize an instance of the shared recognizer.  \n      using (SpeechRecognizer recognizer = new SpeechRecognizer())  \n      {  \n        // Create and load a sample grammar.  \n        Grammar testGrammar =  \n          new Grammar(new GrammarBuilder(\"testing testing\"));  \n        testGrammar.Name = \"Test Grammar\";  \n  \n        recognizer.LoadGrammar(testGrammar);  \n  \n        // Attach event handlers for recognition events.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.EmulateRecognizeCompleted +=  \n          new EventHandler<EmulateRecognizeCompletedEventArgs>(  \n            EmulateRecognizeCompletedHandler);  \n  \n        completed = false;  \n  \n        // This EmulateRecognizeAsync call generates a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing testing\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n  \n        completed = false;  \n  \n        // This EmulateRecognizeAsync call does not match the grammar   \n        // or generate a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing one two three\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"Recognition result = {0}\",  \n          e.Result.Text ?? \"<no text>\");  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No recognition result\");  \n      }  \n    }  \n  \n    // Handle the EmulateRecognizeCompleted event.   \n    static void EmulateRecognizeCompletedHandler(  \n      object sender, EmulateRecognizeCompletedEventArgs e)  \n    {  \n      if (e.Result == null)  \n      {  \n        Console.WriteLine(\"No result generated.\");  \n      }  \n  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void EmulateRecognizeAsync (string inputText);
    parameters:
    - id: inputText
      type: System.String
      description: "輸入辨識作業。"
  overload: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  id: EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  nameWithType: SpeechRecognizer.EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "模擬的特定文字的共用的語音辨識器，使用非同步的語音辨識，而不音訊文字輸入，並指定辨識器如何處理之間的單字與載入的語音辨識文法的 Unicode 比較。"
  remarks: "這個方法會建立<xref:System.Speech.Recognition.RecognitionResult>物件使用所提供的資訊`wordUnits`參數。</xref:System.Speech.Recognition.RecognitionResult>       使用辨識器`compareOptions`套用文法規則進行剖析的輸入句子。 隨附於 Vista 和 Windows 7 的辨識器會忽略大小寫，如果<xref:System.Globalization.CompareOptions>或<xref:System.Globalization.CompareOptions>值存在於。</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> 辨識器一律忽略字元寬度，並永遠不會忽略假名類型。 辨識器也會忽略新行和額外的空白字元和標點符號視為常值的輸入。 如需全半形字元和假名類型的詳細資訊，請參閱<xref:System.Globalization.CompareOptions>列舉型別。</xref:System.Globalization.CompareOptions>"
  syntax:
    content: public void EmulateRecognizeAsync (System.Speech.Recognition.RecognizedWordUnit[] wordUnits, System.Globalization.CompareOptions compareOptions);
    parameters:
    - id: wordUnits
      type: System.Speech.Recognition.RecognizedWordUnit[]
      description: "Word 單位的陣列，其中包含將辨識作業的輸入。"
    - id: compareOptions
      type: System.Globalization.CompareOptions
      description: "描述要用於模擬的辨識作業的比較類型的列舉值的位元組合。"
  overload: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)
  id: EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: EmulateRecognizeAsync(String,CompareOptions)
  nameWithType: SpeechRecognizer.EmulateRecognizeAsync(String,CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(String,CompareOptions)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "模擬片語的共用的語音辨識器，而不音訊使用文字非同步語音辨識的輸入，並指定辨識器如何處理片語與載入的語音辨識文法的 Unicode 比較。"
  remarks: "使用辨識器`compareOptions`套用文法規則進行剖析的輸入句子。 隨附於 Vista 和 Windows 7 的辨識器會忽略大小寫，如果<xref:System.Globalization.CompareOptions>或<xref:System.Globalization.CompareOptions>值存在於。</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> 辨識器一律忽略字元寬度，並永遠不會忽略假名類型。 辨識器也會忽略新行和額外的空白字元和標點符號視為常值的輸入。 如需全半形字元和假名類型的詳細資訊，請參閱<xref:System.Globalization.CompareOptions>列舉型別。</xref:System.Globalization.CompareOptions>"
  syntax:
    content: public void EmulateRecognizeAsync (string inputText, System.Globalization.CompareOptions compareOptions);
    parameters:
    - id: inputText
      type: System.String
      description: "輸入的辨識作業的片語。"
    - id: compareOptions
      type: System.Globalization.CompareOptions
      description: "描述要用於模擬的辨識作業的比較類型的列舉值的位元組合。"
  overload: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted
  id: EmulateRecognizeCompleted
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: EmulateRecognizeCompleted
  nameWithType: SpeechRecognizer.EmulateRecognizeCompleted
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "共用辨識器終結模擬輸入的非同步辨識作業時發生。"
  remarks: "每個<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>方法開始非同步的辨識作業。</xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> 辨識器引發`EmulateRecognizeCompleted`時它結束非同步作業的事件。       非同步辨識作業可能會引發<xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>， <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>， <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>，和<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>事件。</xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected> EmulateRecognizeCompleted 事件是最後一個這類辨識器引發對指定作業的事件。       當您建立的委派`EmulateRecognizeCompleted`事件，必須識別處理事件的方法。 若要將事件與事件處理常式產生關聯，將委派的執行個體加入事件。 除非您移除委派，否則每當事件發生時，會呼叫事件處理常式。 如需事件處理常式委派的詳細資訊，請參閱[事件和委派](http://go.microsoft.com/fwlink/?LinkId=162418)。"
  example:
  - "The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer. If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition. If Windows Speech Recognition is in the **Sleeping** mode, then <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> always returns null.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace SharedRecognizer  \n{  \n  class Program  \n  {  \n    // Indicate whether the asynchronous emulate recognition  \n    // operation has completed.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n  \n      // Initialize an instance of the shared recognizer.  \n      using (SpeechRecognizer recognizer = new SpeechRecognizer())  \n      {  \n        // Create and load a sample grammar.  \n        Grammar testGrammar =  \n          new Grammar(new GrammarBuilder(\"testing testing\"));  \n        testGrammar.Name = \"Test Grammar\";  \n        recognizer.LoadGrammar(testGrammar);  \n  \n        // Attach event handlers for recognition events.  \n        recognizer.SpeechRecognized +=   \n          new EventHandler<SpeechRecognizedEventArgs>(SpeechRecognizedHandler);  \n        recognizer.EmulateRecognizeCompleted +=   \n          new EventHandler<EmulateRecognizeCompletedEventArgs>(  \n            EmulateRecognizeCompletedHandler);  \n  \n        completed = false;  \n  \n        // This EmulateRecognizeAsync call generates a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing testing\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n  \n        completed = false;  \n  \n        // This EmulateRecognizeAsync call does not match the grammar  \n        // or generate a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing one two three\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"Recognition result = {0}\",  \n          e.Result.Text ?? \"<no text>\");  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No recognition result\");  \n      }  \n    }  \n  \n    // Handle the EmulateRecognizeCompleted event.  \n    static void EmulateRecognizeCompletedHandler(  \n      object sender, EmulateRecognizeCompletedEventArgs e)  \n    {  \n      if (e.Result == null)  \n      {  \n        Console.WriteLine(\"No result generated.\");  \n      }  \n  \n      // Indicate the asynchronous operation is complete.  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.EmulateRecognizeCompletedEventArgs> EmulateRecognizeCompleted;
    return:
      type: System.EventHandler{System.Speech.Recognition.EmulateRecognizeCompletedEventArgs}
      description: "即將加入。"
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.Enabled
  id: Enabled
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: Enabled
  nameWithType: SpeechRecognizer.Enabled
  fullName: System.Speech.Recognition.SpeechRecognizer.Enabled
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "取得或設定值，指出是否此<xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;></xref>物件已準備好處理語音。"
  remarks: "變更這個屬性不會影響其他執行個體的<xref:System.Speech.Recognition.SpeechRecognizer>類別。</xref:System.Speech.Recognition.SpeechRecognizer>       根據預設，已啟用屬性的值是`true` <xref:System.Speech.Recognition.SpeechRecognizer>.</xref:System.Speech.Recognition.SpeechRecognizer>的新具現化執行個體 辨識器已停用，而辨識器的語音辨識文法中沒有任何可辨識作業。 設定辨識器的 Enabled 屬性已辨識器不會影響<xref:System.Speech.Recognition.SpeechRecognizer.State%2A>屬性。</xref:System.Speech.Recognition.SpeechRecognizer.State%2A>"
  syntax:
    content: public bool Enabled { get; set; }
    return:
      type: System.Boolean
      description: "<xref uid=&quot;langword_csharp_true&quot; name=&quot;true&quot; href=&quot;&quot;></xref>如果這個<xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;></xref>物件執行語音辨識，否則<xref uid=&quot;langword_csharp_false&quot; name=&quot;false&quot; href=&quot;&quot;> </xref>。"
  overload: System.Speech.Recognition.SpeechRecognizer.Enabled*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.Grammars
  id: Grammars
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: Grammars
  nameWithType: SpeechRecognizer.Grammars
  fullName: System.Speech.Recognition.SpeechRecognizer.Grammars
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "取得集合的<xref href=&quot;System.Speech.Recognition.Grammar&quot;></xref>物件載入這個<xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;></xref>執行個體。"
  remarks: "這個屬性不會傳回任何語音辨識另一個應用程式載入的文法。"
  example:
  - "The following example outputs information to the console for each speech recognition grammar loaded into the shared speech recognizer.  \n  \n```c#  \n  \nusing System;  \nusing System.Collections.Generic;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace SharedRecognizer  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognizer recognizer = new SpeechRecognizer())  \n      {  \n        Grammar sampleGrammar = new Grammar(new GrammarBuilder(\"sample phrase\"));  \n        sampleGrammar.Name = \"Sample Grammar\";  \n        recognizer.LoadGrammar(sampleGrammar);  \n  \n        OutputGrammarList(recognizer);  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    private static void OutputGrammarList(SpeechRecognizer recognizer)  \n    {  \n      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  \n      if (grammars.Count > 0)  \n      {  \n        Console.WriteLine(\"Loaded grammars:\");  \n        foreach (Grammar g in grammars)  \n        {  \n          Console.WriteLine(\"  Grammar: {0}\",  \n            (g.Name != null) ? g.Name : \"<no name>\");  \n        }  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No grammars loaded.\");  \n      }  \n    }  \n}  \n  \n```"
  syntax:
    content: public System.Collections.ObjectModel.ReadOnlyCollection<System.Speech.Recognition.Grammar> Grammars { get; }
    return:
      type: System.Collections.ObjectModel.ReadOnlyCollection{System.Speech.Recognition.Grammar}
      description: "集合<xref href=&quot;System.Speech.Recognition.Grammar&quot;></xref>應用程式載入共用辨識器的目前執行個體的物件。"
  overload: System.Speech.Recognition.SpeechRecognizer.Grammars*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)
  id: LoadGrammar(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: LoadGrammar(Grammar)
  nameWithType: SpeechRecognizer.LoadGrammar(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognizer.LoadGrammar(Grammar)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "載入 語音辨識文法。"
  remarks: "如果語音辨識文法已載入，以非同步方式載入，或無法載入任何辨識器共用辨識器，就會擲回例外狀況。 如果辨識器正在執行，應用程式必須使用<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>暫停之前載入、 卸載、 啟用，或停用文法的語音辨識引擎。</xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>       若要以非同步方式載入語音辨識文法，使用<xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A>方法。</xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A>"
  example:
  - "The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer. If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition. If Windows Speech Recognition is in the **Sleeping** state, then <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> always returns null.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace SharedRecognizer  \n{  \n  class Program  \n  {  \n    // Indicate whether the asynchronous emulate recognition  \n    // operation has completed.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n      // Initialize an instance of the shared recognizer.  \n      using (SpeechRecognizer recognizer = new SpeechRecognizer())  \n      {  \n        // Create and load a sample grammar.  \n        Grammar testGrammar =  \n          new Grammar(new GrammarBuilder(\"testing testing\"));  \n        testGrammar.Name = \"Test Grammar\";  \n  \n        recognizer.LoadGrammar(testGrammar);  \n  \n        // Attach event handlers for recognition events.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.EmulateRecognizeCompleted +=  \n          new EventHandler<EmulateRecognizeCompletedEventArgs>(  \n            EmulateRecognizeCompletedHandler);  \n  \n        completed = false;  \n  \n        // This EmulateRecognizeAsync call generates a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing testing\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n  \n        completed = false;  \n  \n        // This EmulateRecognizeAsync call does not match the grammar   \n        // or generate a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing one two three\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"Recognition result = {0}\",  \n          e.Result.Text ?? \"<no text>\");  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No recognition result\");  \n      }  \n    }   \n  \n    // Handle the EmulateRecognizeCompleted event.   \n    static void EmulateRecognizeCompletedHandler(  \n      object sender, EmulateRecognizeCompletedEventArgs e)  \n    {  \n      if (e.Result == null)  \n      {  \n        Console.WriteLine(\"No result generated.\");  \n      }  \n  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void LoadGrammar (System.Speech.Recognition.Grammar grammar);
    parameters:
    - id: grammar
      type: System.Speech.Recognition.Grammar
      description: "語音辨識文法載入。"
  overload: System.Speech.Recognition.SpeechRecognizer.LoadGrammar*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)
  id: LoadGrammarAsync(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: LoadGrammarAsync(Grammar)
  nameWithType: SpeechRecognizer.LoadGrammarAsync(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(Grammar)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "以非同步方式載入語音辨識文法。"
  remarks: "當辨識器完成這項非同步作業時，會引發<xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted>事件。</xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted> 如果語音辨識文法已載入，以非同步方式載入，或無法載入任何辨識器辨識器，就會擲回例外狀況。 如果辨識器正在執行，應用程式必須使用<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>暫停之前載入、 卸載、 啟用，或停用文法的語音辨識引擎。</xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>       若要以同步方式載入語音辨識文法，使用<xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A>方法。</xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A>"
  syntax:
    content: public void LoadGrammarAsync (System.Speech.Recognition.Grammar grammar);
    parameters:
    - id: grammar
      type: System.Speech.Recognition.Grammar
      description: "語音辨識文法載入。"
  overload: System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted
  id: LoadGrammarCompleted
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: LoadGrammarCompleted
  nameWithType: SpeechRecognizer.LoadGrammarCompleted
  fullName: System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "發生於辨識器完成非同步載入的語音辨識文法。"
  remarks: "辨識器<xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A>方法啟始非同步作業。</xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A> 辨識器引發`LoadGrammarCompleted`完成作業時的事件。 若要取得的<xref:System.Speech.Recognition.Grammar>物件，辨識器載入，使用<xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A>相關聯的<xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs>.</xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs>屬性</xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A></xref:System.Speech.Recognition.Grammar> 若要取得目前<xref:System.Speech.Recognition.Grammar>辨識器載入之後，物件會使用的辨識器<xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A>屬性。</xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A> </xref:System.Speech.Recognition.Grammar>       當您建立的委派`LoadGrammarCompleted`事件，必須識別處理事件的方法。 若要將事件與事件處理常式產生關聯，將委派的執行個體加入事件。 除非您移除委派，否則每當事件發生時，會呼叫事件處理常式。 如需事件處理常式委派的詳細資訊，請參閱[事件和委派](http://go.microsoft.com/fwlink/?LinkId=162418)。"
  example:
  - "The following example creates a shared speech recognizer, and then creates two types of grammars for recognizing specific words and for accepting free dictation. The example asynchronously loads all the created grammars to the recognizer. Handlers for the recognizer's LoadGrammarCompleted and <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> events write to the console the name of the grammar that was used to perform the recognition and the text of the recognition result, respectively.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    private static SpeechRecognizer recognizer;  \n    public static void Main(string[] args)  \n    {  \n  \n      // Initialize a shared speech recognition engine.  \n      recognizer = new SpeechRecognizer();  \n  \n        // Add a handler for the LoadGrammarCompleted event.  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n  \n        // Add a handler for the SpeechRecognized event.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Add a handler for the StateChanged event.  \n        recognizer.StateChanged +=  \n          new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  \n  \n        // Create \"yesno\" grammar.  \n        Choices yesChoices = new Choices(new string[] { \"yes\", \"yup\", \"yeah}\" });  \n        SemanticResultValue yesValue =  \n            new SemanticResultValue(yesChoices, (bool)true);  \n        Choices noChoices = new Choices(new string[] { \"no\", \"nope\", \"neah\" });  \n        SemanticResultValue noValue =  \n            new SemanticResultValue(noChoices, (bool)false);  \n        SemanticResultKey yesNoKey =  \n            new SemanticResultKey(\"yesno\", new Choices(new GrammarBuilder[] { yesValue, noValue }));  \n        Grammar yesnoGrammar = new Grammar(yesNoKey);  \n        yesnoGrammar.Name = \"yesNo\";  \n  \n        // Create \"done\" grammar.  \n        Grammar doneGrammar =  \n          new Grammar(new Choices(new string[] { \"done\", \"exit\", \"quit\", \"stop\" }));  \n        doneGrammar.Name = \"Done\";  \n  \n        // Create dictation grammar.  \n        Grammar dictation = new DictationGrammar();  \n        dictation.Name = \"Dictation\";  \n  \n        // Load grammars to the recognizer.  \n        recognizer.LoadGrammarAsync(yesnoGrammar);  \n        recognizer.LoadGrammarAsync(doneGrammar);  \n        recognizer.LoadGrammarAsync(dictation);  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar({0}): {1}\", e.Result.Grammar.Name, e.Result.Text);  \n  \n      // Add event handler code here.  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.   \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      string grammarName = e.Grammar.Name;  \n      bool grammarLoaded = e.Grammar.Loaded;  \n  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(\"LoadGrammar for {0} failed with a {1}.\",  \n        grammarName, e.Error.GetType().Name);  \n  \n        // Add exception handling code here.  \n      }  \n  \n      Console.WriteLine(\"Grammar {0} {1} loaded.\",  \n      grammarName, (grammarLoaded) ? \"is\" : \"is not\");  \n    }  \n  \n    // Put the shared speech recognizer into \"listening\" mode.   \n    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  \n    {  \n      if (e.RecognizerState != RecognizerState.Stopped)  \n      {  \n        recognizer.EmulateRecognizeAsync(\"Start listening\");  \n      }  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.LoadGrammarCompletedEventArgs> LoadGrammarCompleted;
    return:
      type: System.EventHandler{System.Speech.Recognition.LoadGrammarCompletedEventArgs}
      description: "即將加入。"
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.MaxAlternates
  id: MaxAlternates
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: MaxAlternates
  nameWithType: SpeechRecognizer.MaxAlternates
  fullName: System.Speech.Recognition.SpeechRecognizer.MaxAlternates
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "取得或設定的替代辨識共用辨識器為每個辨識作業傳回的結果數目上限。"
  remarks: "<xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>屬性<xref:System.Speech.Recognition.RecognitionResult>類別包含的集合<xref:System.Speech.Recognition.RecognizedPhrase>物件，表示輸入的其他候選解讀方式。</xref:System.Speech.Recognition.RecognizedPhrase> </xref:System.Speech.Recognition.RecognitionResult> </xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>       MaxAlternates 的預設值為 10。"
  syntax:
    content: public int MaxAlternates { get; set; }
    return:
      type: System.Int32
      description: "替代語音辨識器為每個辨識作業傳回的結果數目上限。"
  overload: System.Speech.Recognition.SpeechRecognizer.MaxAlternates*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition
  id: PauseRecognizerOnRecognition
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: PauseRecognizerOnRecognition
  nameWithType: SpeechRecognizer.PauseRecognizerOnRecognition
  fullName: System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "取得或設定值，指出共用辨識器會辨識作業暫停時應用程式正在處理<xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&quot;></xref>事件。"
  remarks: "將此屬性設定為`true`，如果內<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>應用程式需要變更 語音辨識服務的狀態，或變更載入或啟用語音辨識文法，語音辨識服務處理更多的輸入之前的事件處理常式。</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>      > [!NOTE] > 設定<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>屬性`true`會導致每個<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>封鎖 Windows 語音辨識服務每個應用程式中的事件處理常式。</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>       若要變更同步至共用辨識器與應用程式的狀態，請使用<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>方法。</xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>       PauseRecognizerOnRecognition 時`true`，在執行期間<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>處理常式的語音辨識服務會暫停，到達時加以會緩衝處理新的音訊輸入。</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> 一次<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>事件處理常式結束時，語音辨識服務繼續辨識並開始處理輸入緩衝區的資訊。</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>       若要啟用或停用 語音辨識服務，請使用<xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A>屬性。</xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A>"
  syntax:
    content: public bool PauseRecognizerOnRecognition { get; set; }
    return:
      type: System.Boolean
      description: "<xref uid=&quot;langword_csharp_true&quot; name=&quot;true&quot; href=&quot;&quot;></xref>如果共用辨識器在等待任何應用程式正在處理時，處理輸入<xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&quot;></xref>事件，否則<xref uid=&quot;langword_csharp_false&quot; name=&quot;false&quot; href=&quot;&quot;> </xref>。"
  overload: System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition
  id: RecognizerAudioPosition
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: RecognizerAudioPosition
  nameWithType: SpeechRecognizer.RecognizerAudioPosition
  fullName: System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "取得辨識器音訊輸入它正在處理中的目前位置。"
  remarks: "`RecognizerAudioPosition`屬性會參考在處理其音訊輸入辨識器的位置。 相反地，<xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>屬性會參考其產生的音訊資料流中的輸入的裝置的位置。</xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> 這些位置可能會不同。 例如，如果辨識器已接收輸入它具有不又 RecognizerAudioPosition 屬性的值小於的值，然後產生辨識結果<xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>屬性。</xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>"
  syntax:
    content: public TimeSpan RecognizerAudioPosition { get; }
    return:
      type: System.TimeSpan
      description: "音訊輸入它正在處理中的辨識器位置。"
  overload: System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.RecognizerInfo
  id: RecognizerInfo
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: RecognizerInfo
  nameWithType: SpeechRecognizer.RecognizerInfo
  fullName: System.Speech.Recognition.SpeechRecognizer.RecognizerInfo
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "取得共用的語音辨識器的相關資訊。"
  remarks: "這個屬性會傳回使用中的 Windows 語音辨識語音辨識器的相關資訊。"
  example:
  - "The following example sends information about the shared recognizer to the console.  \n  \n```c#  \n  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SharedRecognizer  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognizer recognizer = new SpeechRecognizer())  \n      {  \n        Console.WriteLine(\"Recognizer information for the shared recognizer:\");  \n        Console.WriteLine(\"  Name: {0}\", recognizer.RecognizerInfo.Name);  \n        Console.WriteLine(\"  Culture: {0}\", recognizer.RecognizerInfo.Culture.ToString());  \n        Console.WriteLine(\"  Description: {0}\", recognizer.RecognizerInfo.Description);  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public System.Speech.Recognition.RecognizerInfo RecognizerInfo { get; }
    return:
      type: System.Speech.Recognition.RecognizerInfo
      description: "共用的語音辨識器的相關資訊。"
  overload: System.Speech.Recognition.SpeechRecognizer.RecognizerInfo*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached
  id: RecognizerUpdateReached
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: RecognizerUpdateReached
  nameWithType: SpeechRecognizer.RecognizerUpdateReached
  fullName: System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "要同步處理辨識和其他作業的辨識器暫停時，就會發生。"
  remarks: "應用程式必須使用<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>暫停的執行個體<xref:System.Speech.Recognition.SpeechRecognizer>之前修改其<xref:System.Speech.Recognition.Grammar>物件。</xref:System.Speech.Recognition.Grammar> </xref:System.Speech.Recognition.SpeechRecognizer> </xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> 例如，雖然<xref:System.Speech.Recognition.SpeechRecognizer>會暫停，您可以載入、 卸載、 啟用和停用<xref:System.Speech.Recognition.Grammar>物件。</xref:System.Speech.Recognition.Grammar> </xref:System.Speech.Recognition.SpeechRecognizer> <xref:System.Speech.Recognition.SpeechRecognizer>引發這個事件時就準備好接受修改。</xref:System.Speech.Recognition.SpeechRecognizer>       當您建立 RecognizerUpdateReached 事件的委派時，您可以識別即將處理此事件的方法。 若要將事件與事件處理常式產生關聯，將委派的執行個體加入事件。 除非您移除委派，否則每當事件發生時，會呼叫事件處理常式。 如需事件處理常式委派的詳細資訊，請參閱[事件和委派](http://go.microsoft.com/fwlink/?LinkId=162418)。"
  example:
  - "The following example shows a console application that loads and unloads <xref:System.Speech.Recognition.Grammar> objects. The application uses the <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> method to request the speech recognition engine to pause so it can receive an update. The application then loads or unloads a <xref:System.Speech.Recognition.Grammar> object.  \n  \n At each update, a handler for RecognizerUpdateReached event writes the name and status of the currently loaded <xref:System.Speech.Recognition.Grammar> objects to the console. As grammars are loaded and unloaded, the application first recognizes the names of farm animals, then the names of farm animals and the names of fruits, then only the names of fruits.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \nusing System.Collections.Generic;  \nusing System.Threading;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    private static SpeechRecognizer recognizer;  \n    public static void Main(string[] args)  \n    {  \n  \n      // Initialize a shared speech recognition engine.  \n      recognizer = new SpeechRecognizer();  \n  \n      // Create the first grammar - Farm.  \n      Choices animals = new Choices(new string[] { \"cow\", \"pig\", \"goat\" });  \n      GrammarBuilder farm = new GrammarBuilder(animals);  \n      Grammar farmAnimals = new Grammar(farm);  \n      farmAnimals.Name = \"Farm\";  \n  \n      // Create the second grammar - Fruit.  \n      Choices fruit = new Choices(new string[] { \"apples\", \"peaches\", \"oranges\" });  \n      GrammarBuilder favorite = new GrammarBuilder(fruit);  \n      Grammar favoriteFruit = new Grammar(favorite);  \n      favoriteFruit.Name = \"Fruit\";  \n  \n      // Attach event handlers.  \n      recognizer.SpeechRecognized +=  \n        new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n      recognizer.RecognizerUpdateReached +=  \n        new EventHandler<RecognizerUpdateReachedEventArgs>(recognizer_RecognizerUpdateReached);  \n      recognizer.StateChanged +=   \n        new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  \n  \n      // Load the Farm grammar.  \n      recognizer.LoadGrammar(farmAnimals);  \n      Console.WriteLine(\"Grammar Farm is loaded\");  \n  \n      // Pause to recognize farm animals.  \n      Thread.Sleep(7000);  \n      Console.WriteLine();  \n  \n      // Request an update and load the Fruit grammar.  \n      recognizer.RequestRecognizerUpdate();  \n      recognizer.LoadGrammarAsync(favoriteFruit);  \n      Thread.Sleep(5000);  \n  \n      // Request an update and unload the Farm grammar.  \n      recognizer.RequestRecognizerUpdate();  \n      recognizer.UnloadGrammar(farmAnimals);  \n      Thread.Sleep(5000);  \n  \n      // Keep the console window open.  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Put the shared speech recognizer into \"listening\" mode.  \n    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  \n    {  \n      if (e.RecognizerState != RecognizerState.Stopped)  \n      {  \n        recognizer.EmulateRecognizeAsync(\"Start listening\");  \n      }  \n    }  \n  \n    // At the update, get the names and enabled status of the currently loaded grammars.  \n    public static void recognizer_RecognizerUpdateReached(  \n      object sender, RecognizerUpdateReachedEventArgs e)  \n    {  \n      Console.WriteLine();  \n      Console.WriteLine(\"Update reached:\");  \n      Thread.Sleep(1000);  \n  \n      string qualifier;  \n      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  \n      foreach (Grammar g in grammars)  \n      {  \n        qualifier = (g.Enabled) ? \"enabled\" : \"disabled\";  \n        Console.WriteLine(\"  Grammar {0} is loaded and is {1}.\",  \n        g.Name, qualifier);  \n      }  \n    }  \n  \n    // Write the text of the recognized phrase to the console.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"  Speech recognized: \" + e.Result.Text);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.RecognizerUpdateReachedEventArgs> RecognizerUpdateReached;
    return:
      type: System.EventHandler{System.Speech.Recognition.RecognizerUpdateReachedEventArgs}
      description: "即將加入。"
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate
  id: RequestRecognizerUpdate
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: RequestRecognizerUpdate()
  nameWithType: SpeechRecognizer.RequestRecognizerUpdate()
  fullName: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "暫停共用辨識器，並更新其狀態的要求。"
  remarks: "當辨識器產生<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>事件，<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A>屬性<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs>是`null`。</xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> </xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> </xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>       若要提供使用者語彙基元，使用<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>或<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>方法。</xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> </xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> 若要指定的音訊位置的位移，請使用<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>方法。</xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>"
  syntax:
    content: public void RequestRecognizerUpdate ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)
  id: RequestRecognizerUpdate(System.Object)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: RequestRecognizerUpdate(Object)
  nameWithType: SpeechRecognizer.RequestRecognizerUpdate(Object)
  fullName: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(Object)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "共用辨識器暫停和更新其狀態並提供相關聯的事件的使用者 token 的要求。"
  remarks: "當辨識器產生<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>事件，<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A>屬性<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs>包含值的`userToken`參數。</xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> </xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> </xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>       若要指定的音訊位置的位移，請使用<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>方法。</xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>"
  syntax:
    content: public void RequestRecognizerUpdate (object userToken);
    parameters:
    - id: userToken
      type: System.Object
      description: "使用者定義的資訊，其中包含作業的資訊。"
  overload: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)
  id: RequestRecognizerUpdate(System.Object,System.TimeSpan)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: RequestRecognizerUpdate(Object,TimeSpan)
  nameWithType: SpeechRecognizer.RequestRecognizerUpdate(Object,TimeSpan)
  fullName: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(Object,TimeSpan)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "共用辨識器暫停和更新其狀態並提供相關聯的事件的位移和使用者 token 的要求。"
  remarks: "辨識器不會啟動辨識器更新要求，直到辨識器<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>等於目前<xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>再加上值`audioPositionAheadToRaiseUpdate`參數。</xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> </xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>       當辨識器產生<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>事件，<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A>屬性<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs>包含值的`userToken`參數。</xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> </xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> </xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>"
  syntax:
    content: public void RequestRecognizerUpdate (object userToken, TimeSpan audioPositionAheadToRaiseUpdate);
    parameters:
    - id: userToken
      type: System.Object
      description: "使用者定義的資訊，其中包含作業的資訊。"
    - id: audioPositionAheadToRaiseUpdate
      type: System.TimeSpan
      description: "從目前的位移<xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition*>延遲要求。</xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition*>"
  overload: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.SpeechDetected
  id: SpeechDetected
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: SpeechDetected
  nameWithType: SpeechRecognizer.SpeechDetected
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechDetected
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "辨識器偵測到它可以將它識別為語音的輸入時發生。"
  remarks: "共用辨識器可能會引發此事件以回應輸入。 <xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A>屬性相關聯的<xref:System.Speech.Recognition.SpeechDetectedEventArgs>物件可指出辨識器偵測到語音輸入資料流中的位置。</xref:System.Speech.Recognition.SpeechDetectedEventArgs> </xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A> 如需詳細資訊，請參閱<xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>和<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>屬性和<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A>和<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>方法。</xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A> </xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> </xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>       當您建立 SpeechDetected 事件的委派時，您可以識別即將處理此事件的方法。 若要將事件與事件處理常式產生關聯，將委派的執行個體加入事件。 除非您移除委派，否則每當事件發生時，會呼叫事件處理常式。 如需事件處理常式委派的詳細資訊，請參閱[事件和委派](http://go.microsoft.com/fwlink/?LinkId=162418)。"
  example:
  - "The following example is part of a console application for choosing origin and destination cities for a flight. The application recognizes phrases such as \"I want to fly from Miami to Chicago.\"  The example uses the SpeechDetected event to report the <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> each time speech is detected.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize a shared speech recognition engine.  \n    {  \n      using (SpeechRecognizer recognizer =  \n         new SpeechRecognizer())  \n      {  \n  \n        // Create a grammar.  \n        Choices cities = new Choices(new string[] {   \n          \"Los Angeles\", \"New York\", \"Chicago\", \"San Francisco\", \"Miami\", \"Dallas\" });  \n  \n        GrammarBuilder gb = new GrammarBuilder();  \n        gb.Append(\"I would like to fly from\");  \n        gb.Append(cities);  \n        gb.Append(\"to\");  \n        gb.Append(cities);  \n  \n        // Create a Grammar object and load it to the recognizer.  \n        Grammar g = new Grammar(gb);  \n        g.Name = (\"City Chooser\");  \n        recognizer.LoadGrammarAsync(g);  \n  \n        // Attach event handlers.  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n        recognizer.SpeechDetected +=   \n          new EventHandler<SpeechDetectedEventArgs>(recognizer_SpeechDetected);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the SpeechDetected event.  \n    static void recognizer_SpeechDetected(object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech detected at AudioPosition = {0}\", e.AudioPosition);  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech recognized: \" + e.Result.Text);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.SpeechDetectedEventArgs> SpeechDetected;
    return:
      type: System.EventHandler{System.Speech.Recognition.SpeechDetectedEventArgs}
      description: "即將加入。"
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized
  id: SpeechHypothesized
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: SpeechHypothesized
  nameWithType: SpeechRecognizer.SpeechHypothesized
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "發生於辨識器已辨識的單字或可能是元件的文法中的多個完整片語的單字。"
  remarks: "共用辨識器可以時引發這個事件的輸入是模稜兩可。 例如支援的其中一個辨識語音辨識文法 」 新遊戲請 」 或 「 新的遊戲，「 」 新遊戲請 」 是模稜兩可的輸入，而 「 新遊戲&quot;模稜兩可的輸入。       當您建立 SpeechHypothesized 事件的委派時，您可以識別即將處理此事件的方法。 若要將事件與事件處理常式產生關聯，將委派的執行個體加入事件。 除非您移除委派，否則每當事件發生時，會呼叫事件處理常式。 如需事件處理常式委派的詳細資訊，請參閱[事件和委派](http://go.microsoft.com/fwlink/?LinkId=162418)。"
  example:
  - "The following example recognizes phrases such as \"Display the list of artists in the jazz category\". The example uses the SpeechHypothesized event to display incomplete phrase fragments in the console as they are recognized.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize a shared speech recognition engine.  \n    {  \n      using (SpeechRecognizer recognizer =  \n         new SpeechRecognizer())  \n      {  \n  \n        // Create a grammar.  \n        //  Create lists of alternative choices.  \n        Choices listTypes = new Choices(new string[] { \"albums\", \"artists\" });  \n        Choices genres = new Choices(new string[] {   \n          \"blues\", \"classical\", \"gospel\", \"jazz\", \"rock\" });  \n  \n        //  Create a GrammarBuilder object and assemble the grammar components.  \n        GrammarBuilder mediaMenu = new GrammarBuilder(\"Display the list of\");  \n        mediaMenu.Append(listTypes);  \n        mediaMenu.Append(\"in the\");  \n        mediaMenu.Append(genres);  \n        mediaMenu.Append(\"category.\");  \n  \n        //  Build a Grammar object from the GrammarBuilder.  \n        Grammar mediaMenuGrammar = new Grammar(mediaMenu);  \n        mediaMenuGrammar.Name = \"Media Chooser\";  \n  \n        // Attach event handlers.  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.SpeechHypothesized +=   \n          new EventHandler<SpeechHypothesizedEventArgs>(recognizer_SpeechHypothesized);  \n  \n        // Load the grammar object to the recognizer.  \n        recognizer.LoadGrammarAsync(mediaMenuGrammar);  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the SpeechHypothesized event.  \n    static void recognizer_SpeechHypothesized(object sender, SpeechHypothesizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech hypothesized: \" + e.Result.Text);  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech recognized: \" + e.Result.Text);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.SpeechHypothesizedEventArgs> SpeechHypothesized;
    return:
      type: System.EventHandler{System.Speech.Recognition.SpeechHypothesizedEventArgs}
      description: "即將加入。"
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected
  id: SpeechRecognitionRejected
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: SpeechRecognitionRejected
  nameWithType: SpeechRecognizer.SpeechRecognitionRejected
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "發生於辨識器收到不符合任何語音辨識文法已載入它的輸入。"
  remarks: "如果它決定輸入不符合足夠放心地載入的語音辨識任何的文法共用辨識器會引發這個事件。 <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>屬性<xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>包含拒絕<xref:System.Speech.Recognition.RecognitionResult>物件。</xref:System.Speech.Recognition.RecognitionResult> </xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> </xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>       共用辨識器所管理的信賴閾值<xref:System.Speech.Recognition.SpeechRecognizer>、 相關聯的使用者設定檔和 Windows 登錄中儲存。</xref:System.Speech.Recognition.SpeechRecognizer> 應用程式應該不會寫入登錄的共用辨識器的屬性變更。       當您建立 SpeechRecognitionRejected 事件的委派時，您可以識別即將處理此事件的方法。 若要將事件與事件處理常式產生關聯，將委派的執行個體加入事件。 除非您移除委派，否則每當事件發生時，會呼叫事件處理常式。 如需事件處理常式委派的詳細資訊，請參閱[事件和委派](http://go.microsoft.com/fwlink/?LinkId=162418)。"
  example:
  - "The following example recognizes phrases such as \"Display the list of artists in the jazz category\" or \"Display albums gospel\". The example uses a handler for the SpeechRecognitionRejected event to display a notification in the console when the speech input cannot be matched to the contents of the grammar with sufficient confidence to produce a successful recognition.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize a shared speech recognition engine.  \n    {  \n      using (SpeechRecognizer recognizer =  \n         new SpeechRecognizer())  \n      {  \n  \n        // Create a grammar.  \n        //  Create lists of alternative choices.  \n        Choices listTypes = new Choices(new string[] { \"albums\", \"artists\" });  \n        Choices genres = new Choices(new string[] {   \n          \"blues\", \"classical\", \"gospel\", \"jazz\", \"rock\" });  \n  \n        //  Create a GrammarBuilder object and assemble the grammar components.  \n        GrammarBuilder mediaMenu = new GrammarBuilder(\"Display\");  \n        mediaMenu.Append(\"the list of\", 0, 1);  \n        mediaMenu.Append(listTypes);  \n        mediaMenu.Append(\"in the\", 0, 1);  \n        mediaMenu.Append(genres);  \n        mediaMenu.Append(\"category\", 0, 1);  \n  \n        //  Build a Grammar object from the GrammarBuilder.  \n        Grammar mediaMenuGrammar = new Grammar(mediaMenu);  \n        mediaMenuGrammar.Name = \"Media Chooser\";  \n  \n        // Attach event handlers.  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.SpeechRecognitionRejected +=   \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(recognizer_SpeechRecognitionRejected);  \n  \n        // Load the grammar object to the recognizer.  \n        recognizer.LoadGrammarAsync(mediaMenuGrammar);  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the SpeechRecognitionRejected event.  \n    static void recognizer_SpeechRecognitionRejected(object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech input was rejected.\");  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech recognized: \" + e.Result.Text);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> SpeechRecognitionRejected;
    return:
      type: System.EventHandler{System.Speech.Recognition.SpeechRecognitionRejectedEventArgs}
      description: "即將加入。"
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.SpeechRecognized
  id: SpeechRecognized
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: SpeechRecognized
  nameWithType: SpeechRecognizer.SpeechRecognized
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechRecognized
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "發生於辨識器收到符合其語音辨識文法的其中一個輸入。"
  remarks: "辨識器引發`SpeechRecognized`事件，如果它有足夠的信心地輸入符合其中一個已載入及啟用語音辨識文法所決定。 <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>屬性<xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>包含接受<xref:System.Speech.Recognition.RecognitionResult>物件。</xref:System.Speech.Recognition.RecognitionResult> </xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> </xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>       共用辨識器所管理的信賴閾值<xref:System.Speech.Recognition.SpeechRecognizer>、 相關聯的使用者設定檔和 Windows 登錄中儲存。</xref:System.Speech.Recognition.SpeechRecognizer> 應用程式應該不會寫入登錄的共用辨識器的屬性變更。       當辨識器收到符合文法中，輸入<xref:System.Speech.Recognition.Grammar>物件可以引發<xref:System.Speech.Recognition.Grammar.SpeechRecognized>事件。</xref:System.Speech.Recognition.Grammar.SpeechRecognized> </xref:System.Speech.Recognition.Grammar> <xref:System.Speech.Recognition.Grammar>物件的<xref:System.Speech.Recognition.Grammar.SpeechRecognized>語音辨識器 SpeechRecognized 事件之前引發事件。</xref:System.Speech.Recognition.Grammar.SpeechRecognized> </xref:System.Speech.Recognition.Grammar>       當您建立 SpeechRecognized 事件的委派時，您可以識別即將處理此事件的方法。 若要將事件與事件處理常式產生關聯，將委派的執行個體加入事件。 除非您移除委派，否則每當事件發生時，會呼叫事件處理常式。 如需事件處理常式委派的詳細資訊，請參閱[事件和委派](http://go.microsoft.com/fwlink/?LinkId=162418)。"
  example:
  - "The following example is part of a console application that loads a speech recognition grammar and demonstrates speech input to the shared recognizer, the associated recognition results, and the associated events raised by the speech recognizer. If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.  \n  \n Spoken input such as \"I want to fly from Chicago to Miami\" will trigger a SpeechRecognized event. Speaking the phrase \"Fly me from Houston to Chicago \" will not trigger a SpeechRecognized event.  \n  \n The example uses a handler for the SpeechRecognized event to display successfully recognized phrases and the semantics they contain in the console.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize a shared speech recognition engine.  \n    {  \n      using (SpeechRecognizer recognizer = new SpeechRecognizer())  \n      {  \n  \n        // Create SemanticResultValue objects that contain cities and airport codes.  \n        SemanticResultValue chicago = new SemanticResultValue(\"Chicago\", \"ORD\");  \n        SemanticResultValue boston = new SemanticResultValue(\"Boston\", \"BOS\");  \n        SemanticResultValue miami = new SemanticResultValue(\"Miami\", \"MIA\");  \n        SemanticResultValue dallas = new SemanticResultValue(\"Dallas\", \"DFW\");  \n  \n        // Create a Choices object and add the SemanticResultValue objects, using  \n        // implicit conversion from SemanticResultValue to GrammarBuilder  \n        Choices cities = new Choices();  \n        cities.Add(new Choices(new GrammarBuilder[] { chicago, boston, miami, dallas }));  \n  \n        // Build the phrase and add SemanticResultKeys.  \n        GrammarBuilder chooseCities = new GrammarBuilder();  \n        chooseCities.Append(\"I want to fly from\");  \n        chooseCities.Append(new SemanticResultKey(\"origin\", cities));  \n        chooseCities.Append(\"to\");  \n        chooseCities.Append(new SemanticResultKey(\"destination\", cities));  \n  \n        // Build a Grammar object from the GrammarBuilder.  \n        Grammar bookFlight = new Grammar(chooseCities);  \n        bookFlight.Name = \"Book Flight\";  \n  \n        // Add a handler for the LoadGrammarCompleted event.  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n  \n        // Add a handler for the SpeechRecognized event.  \n        recognizer.SpeechRecognized +=   \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Load the grammar object to the recognizer.  \n        recognizer.LoadGrammarAsync(bookFlight);  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n      Console.WriteLine();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech recognized:  \" + e.Result.Text);  \n      Console.WriteLine();  \n      Console.WriteLine(\"Semantic results:\");  \n      Console.WriteLine(\"  The flight origin is \" + e.Result.Semantics[\"origin\"].Value);  \n      Console.WriteLine(\"  The flight destination is \" + e.Result.Semantics[\"destination\"].Value);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.SpeechRecognizedEventArgs> SpeechRecognized;
    return:
      type: System.EventHandler{System.Speech.Recognition.SpeechRecognizedEventArgs}
      description: "即將加入。"
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.State
  id: State
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: State
  nameWithType: SpeechRecognizer.State
  fullName: System.Speech.Recognition.SpeechRecognizer.State
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "取得狀態<xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;></xref>物件。"
  remarks: "這個唯讀屬性會指出位於 Windows 共用的辨識器是否處於`Stopped`或`Listening`狀態。 如需詳細資訊，請參閱<xref:System.Speech.Recognition.RecognizerState>列舉型別。</xref:System.Speech.Recognition.RecognizerState>"
  syntax:
    content: public System.Speech.Recognition.RecognizerState State { get; }
    return:
      type: System.Speech.Recognition.RecognizerState
      description: "狀態<xref uid=&quot;langword_csharp_SpeechRecognizer&quot; name=&quot;SpeechRecognizer&quot; href=&quot;&quot;></xref>物件。"
  overload: System.Speech.Recognition.SpeechRecognizer.State*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.StateChanged
  id: StateChanged
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: StateChanged
  nameWithType: SpeechRecognizer.StateChanged
  fullName: System.Speech.Recognition.SpeechRecognizer.StateChanged
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Windows 桌面語音技術辨識引擎的執行狀態變更時發生。"
  remarks: "共用辨識器引發這個事件的 Windows 語音辨識狀態變更為<xref:System.Speech.Recognition.RecognizerState>或<xref:System.Speech.Recognition.RecognizerState>狀態。</xref:System.Speech.Recognition.RecognizerState> </xref:System.Speech.Recognition.RecognizerState>       若要共用辨識器的狀態事件時，使用<xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A>相關聯的<xref:System.Speech.Recognition.StateChangedEventArgs>.</xref:System.Speech.Recognition.StateChangedEventArgs>屬性</xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A> 若要取得共用辨識器的目前狀態，請使用 辨識器<xref:System.Speech.Recognition.SpeechRecognizer.State%2A>屬性。</xref:System.Speech.Recognition.SpeechRecognizer.State%2A>       當您建立 StateChanged 事件的委派時，您可以識別即將處理此事件的方法。 若要將事件與事件處理常式產生關聯，將委派的執行個體加入事件。 除非您移除委派，否則每當事件發生時，會呼叫事件處理常式。 如需事件處理常式委派的詳細資訊，請參閱[事件和委派](http://go.microsoft.com/fwlink/?LinkId=162418)。"
  example:
  - "The following example creates a shared speech recognizer, and then creates two types of grammars for recognizing specific words and for accepting free dictation. The example asynchronously loads all the created grammars to the recognizer.  A handler for the StateChanged event uses the <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> method to put Windows Recognition in \"listening\" mode.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    private static SpeechRecognizer recognizer;  \n    public static void Main(string[] args)  \n    {  \n  \n      // Initialize a shared speech recognition engine.  \n      recognizer = new SpeechRecognizer();  \n  \n      // Add a handler for the LoadGrammarCompleted event.  \n      recognizer.LoadGrammarCompleted += new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n  \n      // Add a handler for the SpeechRecognized event.  \n      recognizer.SpeechRecognized += new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n      // Add a handler for the StateChanged event.  \n      recognizer.StateChanged += new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  \n  \n      // Create \"yesno\" grammar.  \n      Choices yesChoices = new Choices(new string[] { \"yes\", \"yup\", \"yah}\" });  \n      SemanticResultValue yesValue =  \n          new SemanticResultValue(yesChoices, (bool)true);  \n      Choices noChoices = new Choices(new string[] { \"no\", \"nope\", \"nah\" });  \n      SemanticResultValue noValue = new SemanticResultValue(noChoices, (bool)false);  \n      SemanticResultKey yesNoKey =  \n          new SemanticResultKey(\"yesno\", new Choices(new GrammarBuilder[] { yesValue, noValue }));  \n      Grammar yesnoGrammar = new Grammar(yesNoKey);  \n      yesnoGrammar.Name = \"yesNo\";  \n  \n      // Create \"done\" grammar.  \n      Grammar doneGrammar =  \n        new Grammar(new Choices(new string[] { \"done\", \"exit\", \"quit\", \"stop\" }));  \n      doneGrammar.Name = \"Done\";  \n  \n      // Create dictation grammar.  \n      Grammar dictation = new DictationGrammar();  \n      dictation.Name = \"Dictation\";  \n  \n      // Load grammars to the recognizer.  \n      recognizer.LoadGrammarAsync(yesnoGrammar);  \n      recognizer.LoadGrammarAsync(doneGrammar);  \n      recognizer.LoadGrammarAsync(dictation);  \n  \n      // Keep the console window open.  \n      Console.ReadLine();  \n    }  \n  \n    // Put the shared speech recognizer into \"listening\" mode.  \n    static void  recognizer_StateChanged(object sender, StateChangedEventArgs e)  \n    {  \n     if (e.RecognizerState != RecognizerState.Stopped)  \n      {  \n        recognizer.EmulateRecognizeAsync(\"Start listening\");  \n      }  \n    }  \n  \n    // Write the text of the recognized phrase to the console.  \n    static void  recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n     Console.WriteLine(\"Grammar({0}): {1}\", e.Result.Grammar.Name, e.Result.Text);  \n  \n      // Add event handler code here.  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void  recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n     string grammarName = e.Grammar.Name;  \n      bool grammarLoaded = e.Grammar.Loaded;  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(\"LoadGrammar for {0} failed with a {1}.\",  \n        grammarName, e.Error.GetType().Name);  \n      }  \n  \n      // Add exception handling code here.  \n      Console.WriteLine(\"Grammar {0} {1} loaded.\",  \n      grammarName, (grammarLoaded) ? \"is\" : \"is not\");  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.StateChangedEventArgs> StateChanged;
    return:
      type: System.EventHandler{System.Speech.Recognition.StateChangedEventArgs}
      description: "即將加入。"
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars
  id: UnloadAllGrammars
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: UnloadAllGrammars()
  nameWithType: SpeechRecognizer.UnloadAllGrammars()
  fullName: System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "卸載所有的語音辨識文法，從共用辨識器。"
  remarks: "如果辨識器正在以非同步方式載入文法，這個方法會等候直到載入文法時之前它卸載所有的辨識器的文法。       若要卸除特定文法，請使用<xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A>方法。</xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A>"
  syntax:
    content: public void UnloadAllGrammars ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)
  id: UnloadGrammar(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: UnloadGrammar(Grammar)
  nameWithType: SpeechRecognizer.UnloadGrammar(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(Grammar)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "卸載共用辨識器從指定的語音辨識文法。"
  remarks: "如果辨識器正在執行，應用程式必須使用<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>暫停之前載入、 卸載、 啟用，或停用文法的語音辨識引擎。</xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> 若要卸除所有的文法，請使用<xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A>方法。</xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A>"
  syntax:
    content: public void UnloadGrammar (System.Speech.Recognition.Grammar grammar);
    parameters:
    - id: grammar
      type: System.Speech.Recognition.Grammar
      description: "卸載文法。"
  overload: System.Speech.Recognition.SpeechRecognizer.UnloadGrammar*
  exceptions: []
  platform:
  - net462
references:
- uid: System.Object
  isExternal: false
  name: System.Object
- uid: System.Speech.Recognition.SpeechRecognizer.#ctor
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: SpeechRecognizer()
  nameWithType: SpeechRecognizer.SpeechRecognizer()
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechRecognizer()
- uid: System.Speech.Recognition.SpeechRecognizer.AudioFormat
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioFormat
  nameWithType: SpeechRecognizer.AudioFormat
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioFormat
- uid: System.Speech.AudioFormat.SpeechAudioFormatInfo
  parent: System.Speech.AudioFormat
  isExternal: false
  name: SpeechAudioFormatInfo
  nameWithType: SpeechAudioFormatInfo
  fullName: System.Speech.AudioFormat.SpeechAudioFormatInfo
- uid: System.Speech.Recognition.SpeechRecognizer.AudioLevel
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioLevel
  nameWithType: SpeechRecognizer.AudioLevel
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioLevel
- uid: System.Int32
  parent: System
  isExternal: true
  name: Int32
  nameWithType: Int32
  fullName: System.Int32
- uid: System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioLevelUpdated
  nameWithType: SpeechRecognizer.AudioLevelUpdated
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated
- uid: System.EventHandler{System.Speech.Recognition.AudioLevelUpdatedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<AudioLevelUpdatedEventArgs>
  nameWithType: EventHandler<AudioLevelUpdatedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.AudioLevelUpdatedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.AudioLevelUpdatedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.AudioLevelUpdatedEventArgs
    name: AudioLevelUpdatedEventArgs
    nameWithType: AudioLevelUpdatedEventArgs
    fullName: AudioLevelUpdatedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.AudioPosition
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioPosition
  nameWithType: SpeechRecognizer.AudioPosition
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioPosition
- uid: System.TimeSpan
  parent: System
  isExternal: true
  name: TimeSpan
  nameWithType: TimeSpan
  fullName: System.TimeSpan
- uid: System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioSignalProblemOccurred
  nameWithType: SpeechRecognizer.AudioSignalProblemOccurred
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred
- uid: System.EventHandler{System.Speech.Recognition.AudioSignalProblemOccurredEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<AudioSignalProblemOccurredEventArgs>
  nameWithType: EventHandler<AudioSignalProblemOccurredEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.AudioSignalProblemOccurredEventArgs
    name: AudioSignalProblemOccurredEventArgs
    nameWithType: AudioSignalProblemOccurredEventArgs
    fullName: AudioSignalProblemOccurredEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.AudioState
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioState
  nameWithType: SpeechRecognizer.AudioState
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioState
- uid: System.Speech.Recognition.AudioState
  parent: System.Speech.Recognition
  isExternal: false
  name: AudioState
  nameWithType: AudioState
  fullName: System.Speech.Recognition.AudioState
- uid: System.Speech.Recognition.SpeechRecognizer.AudioStateChanged
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioStateChanged
  nameWithType: SpeechRecognizer.AudioStateChanged
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioStateChanged
- uid: System.EventHandler{System.Speech.Recognition.AudioStateChangedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<AudioStateChangedEventArgs>
  nameWithType: EventHandler<AudioStateChangedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.AudioStateChangedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.AudioStateChangedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.AudioStateChangedEventArgs
    name: AudioStateChangedEventArgs
    nameWithType: AudioStateChangedEventArgs
    fullName: AudioStateChangedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.Dispose
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: Dispose()
  nameWithType: SpeechRecognizer.Dispose()
  fullName: System.Speech.Recognition.SpeechRecognizer.Dispose()
- uid: System.Speech.Recognition.SpeechRecognizer.Dispose(System.Boolean)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: Dispose(Boolean)
  nameWithType: SpeechRecognizer.Dispose(Boolean)
  fullName: System.Speech.Recognition.SpeechRecognizer.Dispose(Boolean)
- uid: System.Boolean
  parent: System
  isExternal: true
  name: Boolean
  nameWithType: Boolean
  fullName: System.Boolean
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: EmulateRecognize(String)
  nameWithType: SpeechRecognizer.EmulateRecognize(String)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(String)
- uid: System.Speech.Recognition.RecognitionResult
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognitionResult
  nameWithType: RecognitionResult
  fullName: System.Speech.Recognition.RecognitionResult
- uid: System.String
  parent: System
  isExternal: true
  name: String
  nameWithType: String
  fullName: System.String
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  nameWithType: SpeechRecognizer.EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(RecognizedWordUnit[],CompareOptions)
- uid: System.Speech.Recognition.RecognizedWordUnit[]
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognizedWordUnit
  nameWithType: RecognizedWordUnit
  fullName: System.Speech.Recognition.RecognizedWordUnit[]
  spec.csharp:
  - uid: System.Speech.Recognition.RecognizedWordUnit
    name: RecognizedWordUnit
    nameWithType: RecognizedWordUnit
    fullName: RecognizedWordUnit[]
  - name: '[]'
    nameWithType: '[]'
    fullName: '[]'
- uid: System.Globalization.CompareOptions
  parent: System.Globalization
  isExternal: true
  name: CompareOptions
  nameWithType: CompareOptions
  fullName: System.Globalization.CompareOptions
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: EmulateRecognize(String,CompareOptions)
  nameWithType: SpeechRecognizer.EmulateRecognize(String,CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(String,CompareOptions)
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: EmulateRecognizeAsync(String)
  nameWithType: SpeechRecognizer.EmulateRecognizeAsync(String)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(String)
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  nameWithType: SpeechRecognizer.EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: EmulateRecognizeAsync(String,CompareOptions)
  nameWithType: SpeechRecognizer.EmulateRecognizeAsync(String,CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(String,CompareOptions)
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: EmulateRecognizeCompleted
  nameWithType: SpeechRecognizer.EmulateRecognizeCompleted
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted
- uid: System.EventHandler{System.Speech.Recognition.EmulateRecognizeCompletedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<EmulateRecognizeCompletedEventArgs>
  nameWithType: EventHandler<EmulateRecognizeCompletedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.EmulateRecognizeCompletedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.EmulateRecognizeCompletedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.EmulateRecognizeCompletedEventArgs
    name: EmulateRecognizeCompletedEventArgs
    nameWithType: EmulateRecognizeCompletedEventArgs
    fullName: EmulateRecognizeCompletedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.Enabled
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: Enabled
  nameWithType: SpeechRecognizer.Enabled
  fullName: System.Speech.Recognition.SpeechRecognizer.Enabled
- uid: System.Speech.Recognition.SpeechRecognizer.Grammars
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: Grammars
  nameWithType: SpeechRecognizer.Grammars
  fullName: System.Speech.Recognition.SpeechRecognizer.Grammars
- uid: System.Collections.ObjectModel.ReadOnlyCollection{System.Speech.Recognition.Grammar}
  parent: System.Collections.ObjectModel
  isExternal: true
  name: ReadOnlyCollection<Grammar>
  nameWithType: ReadOnlyCollection<Grammar>
  fullName: System.Collections.ObjectModel.ReadOnlyCollection<System.Speech.Recognition.Grammar>
  spec.csharp:
  - uid: System.Collections.ObjectModel.ReadOnlyCollection`1
    name: ReadOnlyCollection
    nameWithType: ReadOnlyCollection
    fullName: ReadOnlyCollection<System.Speech.Recognition.Grammar>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.Grammar
    name: Grammar
    nameWithType: Grammar
    fullName: Grammar
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: LoadGrammar(Grammar)
  nameWithType: SpeechRecognizer.LoadGrammar(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognizer.LoadGrammar(Grammar)
- uid: System.Speech.Recognition.Grammar
  parent: System.Speech.Recognition
  isExternal: false
  name: Grammar
  nameWithType: Grammar
  fullName: System.Speech.Recognition.Grammar
- uid: System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: LoadGrammarAsync(Grammar)
  nameWithType: SpeechRecognizer.LoadGrammarAsync(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(Grammar)
- uid: System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: LoadGrammarCompleted
  nameWithType: SpeechRecognizer.LoadGrammarCompleted
  fullName: System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted
- uid: System.EventHandler{System.Speech.Recognition.LoadGrammarCompletedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<LoadGrammarCompletedEventArgs>
  nameWithType: EventHandler<LoadGrammarCompletedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.LoadGrammarCompletedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.LoadGrammarCompletedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.LoadGrammarCompletedEventArgs
    name: LoadGrammarCompletedEventArgs
    nameWithType: LoadGrammarCompletedEventArgs
    fullName: LoadGrammarCompletedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.MaxAlternates
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: MaxAlternates
  nameWithType: SpeechRecognizer.MaxAlternates
  fullName: System.Speech.Recognition.SpeechRecognizer.MaxAlternates
- uid: System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: PauseRecognizerOnRecognition
  nameWithType: SpeechRecognizer.PauseRecognizerOnRecognition
  fullName: System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition
- uid: System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: RecognizerAudioPosition
  nameWithType: SpeechRecognizer.RecognizerAudioPosition
  fullName: System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition
- uid: System.Speech.Recognition.SpeechRecognizer.RecognizerInfo
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: RecognizerInfo
  nameWithType: SpeechRecognizer.RecognizerInfo
  fullName: System.Speech.Recognition.SpeechRecognizer.RecognizerInfo
- uid: System.Speech.Recognition.RecognizerInfo
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognizerInfo
  nameWithType: RecognizerInfo
  fullName: System.Speech.Recognition.RecognizerInfo
- uid: System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: RecognizerUpdateReached
  nameWithType: SpeechRecognizer.RecognizerUpdateReached
  fullName: System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached
- uid: System.EventHandler{System.Speech.Recognition.RecognizerUpdateReachedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<RecognizerUpdateReachedEventArgs>
  nameWithType: EventHandler<RecognizerUpdateReachedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.RecognizerUpdateReachedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.RecognizerUpdateReachedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.RecognizerUpdateReachedEventArgs
    name: RecognizerUpdateReachedEventArgs
    nameWithType: RecognizerUpdateReachedEventArgs
    fullName: RecognizerUpdateReachedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: RequestRecognizerUpdate()
  nameWithType: SpeechRecognizer.RequestRecognizerUpdate()
  fullName: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate()
- uid: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: RequestRecognizerUpdate(Object)
  nameWithType: SpeechRecognizer.RequestRecognizerUpdate(Object)
  fullName: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(Object)
- uid: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: RequestRecognizerUpdate(Object,TimeSpan)
  nameWithType: SpeechRecognizer.RequestRecognizerUpdate(Object,TimeSpan)
  fullName: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(Object,TimeSpan)
- uid: System.Speech.Recognition.SpeechRecognizer.SpeechDetected
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: SpeechDetected
  nameWithType: SpeechRecognizer.SpeechDetected
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechDetected
- uid: System.EventHandler{System.Speech.Recognition.SpeechDetectedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<SpeechDetectedEventArgs>
  nameWithType: EventHandler<SpeechDetectedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.SpeechDetectedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.SpeechDetectedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.SpeechDetectedEventArgs
    name: SpeechDetectedEventArgs
    nameWithType: SpeechDetectedEventArgs
    fullName: SpeechDetectedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: SpeechHypothesized
  nameWithType: SpeechRecognizer.SpeechHypothesized
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized
- uid: System.EventHandler{System.Speech.Recognition.SpeechHypothesizedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<SpeechHypothesizedEventArgs>
  nameWithType: EventHandler<SpeechHypothesizedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.SpeechHypothesizedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.SpeechHypothesizedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.SpeechHypothesizedEventArgs
    name: SpeechHypothesizedEventArgs
    nameWithType: SpeechHypothesizedEventArgs
    fullName: SpeechHypothesizedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: SpeechRecognitionRejected
  nameWithType: SpeechRecognizer.SpeechRecognitionRejected
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected
- uid: System.EventHandler{System.Speech.Recognition.SpeechRecognitionRejectedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<SpeechRecognitionRejectedEventArgs>
  nameWithType: EventHandler<SpeechRecognitionRejectedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.SpeechRecognitionRejectedEventArgs
    name: SpeechRecognitionRejectedEventArgs
    nameWithType: SpeechRecognitionRejectedEventArgs
    fullName: SpeechRecognitionRejectedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.SpeechRecognized
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: SpeechRecognized
  nameWithType: SpeechRecognizer.SpeechRecognized
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechRecognized
- uid: System.EventHandler{System.Speech.Recognition.SpeechRecognizedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<SpeechRecognizedEventArgs>
  nameWithType: EventHandler<SpeechRecognizedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.SpeechRecognizedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.SpeechRecognizedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.SpeechRecognizedEventArgs
    name: SpeechRecognizedEventArgs
    nameWithType: SpeechRecognizedEventArgs
    fullName: SpeechRecognizedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.State
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: State
  nameWithType: SpeechRecognizer.State
  fullName: System.Speech.Recognition.SpeechRecognizer.State
- uid: System.Speech.Recognition.RecognizerState
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognizerState
  nameWithType: RecognizerState
  fullName: System.Speech.Recognition.RecognizerState
- uid: System.Speech.Recognition.SpeechRecognizer.StateChanged
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: StateChanged
  nameWithType: SpeechRecognizer.StateChanged
  fullName: System.Speech.Recognition.SpeechRecognizer.StateChanged
- uid: System.EventHandler{System.Speech.Recognition.StateChangedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<StateChangedEventArgs>
  nameWithType: EventHandler<StateChangedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.StateChangedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.StateChangedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.StateChangedEventArgs
    name: StateChangedEventArgs
    nameWithType: StateChangedEventArgs
    fullName: StateChangedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: UnloadAllGrammars()
  nameWithType: SpeechRecognizer.UnloadAllGrammars()
  fullName: System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars()
- uid: System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: UnloadGrammar(Grammar)
  nameWithType: SpeechRecognizer.UnloadGrammar(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(Grammar)
- uid: System.Speech.Recognition.SpeechRecognizer.#ctor*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: SpeechRecognizer
  nameWithType: SpeechRecognizer.SpeechRecognizer
- uid: System.Speech.Recognition.SpeechRecognizer.AudioFormat*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioFormat
  nameWithType: SpeechRecognizer.AudioFormat
- uid: System.Speech.Recognition.SpeechRecognizer.AudioLevel*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioLevel
  nameWithType: SpeechRecognizer.AudioLevel
- uid: System.Speech.Recognition.SpeechRecognizer.AudioPosition*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioPosition
  nameWithType: SpeechRecognizer.AudioPosition
- uid: System.Speech.Recognition.SpeechRecognizer.AudioState*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioState
  nameWithType: SpeechRecognizer.AudioState
- uid: System.Speech.Recognition.SpeechRecognizer.Dispose*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: Dispose
  nameWithType: SpeechRecognizer.Dispose
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: EmulateRecognize
  nameWithType: SpeechRecognizer.EmulateRecognize
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: EmulateRecognizeAsync
  nameWithType: SpeechRecognizer.EmulateRecognizeAsync
- uid: System.Speech.Recognition.SpeechRecognizer.Enabled*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: Enabled
  nameWithType: SpeechRecognizer.Enabled
- uid: System.Speech.Recognition.SpeechRecognizer.Grammars*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: Grammars
  nameWithType: SpeechRecognizer.Grammars
- uid: System.Speech.Recognition.SpeechRecognizer.LoadGrammar*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: LoadGrammar
  nameWithType: SpeechRecognizer.LoadGrammar
- uid: System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: LoadGrammarAsync
  nameWithType: SpeechRecognizer.LoadGrammarAsync
- uid: System.Speech.Recognition.SpeechRecognizer.MaxAlternates*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: MaxAlternates
  nameWithType: SpeechRecognizer.MaxAlternates
- uid: System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: PauseRecognizerOnRecognition
  nameWithType: SpeechRecognizer.PauseRecognizerOnRecognition
- uid: System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: RecognizerAudioPosition
  nameWithType: SpeechRecognizer.RecognizerAudioPosition
- uid: System.Speech.Recognition.SpeechRecognizer.RecognizerInfo*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: RecognizerInfo
  nameWithType: SpeechRecognizer.RecognizerInfo
- uid: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: RequestRecognizerUpdate
  nameWithType: SpeechRecognizer.RequestRecognizerUpdate
- uid: System.Speech.Recognition.SpeechRecognizer.State*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: State
  nameWithType: SpeechRecognizer.State
- uid: System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: UnloadAllGrammars
  nameWithType: SpeechRecognizer.UnloadAllGrammars
- uid: System.Speech.Recognition.SpeechRecognizer.UnloadGrammar*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: UnloadGrammar
  nameWithType: SpeechRecognizer.UnloadGrammar
